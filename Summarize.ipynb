{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lec02 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step1. Build a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = X*W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step2. Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2.02039e-07 [ 1.00029087] [ 0.99895006]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    costvalue, weight, bvalue, _ = sess.run([cost, W, b, train],\n",
    "                                           feed_dict ={X:[1,2,3,4,5],Y:[2,3,4,5,6]})\n",
    "print(step, costvalue, weight, bvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step3. Clost the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lec03 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step1. Build a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "X = tf.placeholder('float', shape=[None])\n",
    "Y = tf.placeholder('float', shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = X*W\n",
    "cost = tf.reduce_sum(tf.square(hypothesis-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수 tensor에는 =로 assign할 수 없음, 대신 W.assign(descent) 이용\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W*X-Y)*X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step2. Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [2,4,3]\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.45821 [ 1.28674519]\n",
      "3.28367 [ 1.31959748]\n",
      "3.23402 [ 1.33711863]\n",
      "3.2199 [ 1.34646332]\n",
      "3.21588 [ 1.35144711]\n",
      "3.21474 [ 1.35410511]\n",
      "3.21442 [ 1.35552275]\n",
      "3.21432 [ 1.35627878]\n",
      "3.2143 [ 1.35668206]\n",
      "3.21429 [ 1.35689712]\n",
      "3.21429 [ 1.3570118]\n",
      "3.21429 [ 1.35707295]\n",
      "3.21429 [ 1.35710561]\n",
      "3.21429 [ 1.35712302]\n",
      "3.21429 [ 1.35713232]\n",
      "3.21429 [ 1.3571372]\n",
      "3.21429 [ 1.35713983]\n",
      "3.21429 [ 1.35714126]\n",
      "3.21429 [ 1.35714197]\n",
      "3.21429 [ 1.35714233]\n",
      "3.21429 [ 1.35714257]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n",
      "3.21429 [ 1.35714269]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "     # sess.run에 train = optimizer.minimize(cost)를 넣듯이 update를 넣어줘야함\n",
    "    costvalue, weight, _ = sess.run([cost, W, update], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100:\n",
    "        print(costvalue, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step3. closs session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lec04 multi-variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step1. Build a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "W = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X,W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.00001)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step2. run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[73, 80, 75],[93,88,93],[89,91,90],[96,98,100],[73,66,70]]\n",
    "y_data = [152,185,180,196,142]\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100457.0 [[ 0.26280594]\n",
      " [ 0.4988429 ]\n",
      " [-0.84219414]] [ 0.75370282]\n",
      "100 825.63 [[ 0.98672915]\n",
      " [ 1.17056525]\n",
      " [-0.17441455]] [ 0.76659632]\n",
      "200 823.351 [[ 1.02480853]\n",
      " [ 1.15825796]\n",
      " [-0.19995904]] [ 0.7715078]\n",
      "300 821.124 [[ 1.06236219]\n",
      " [ 1.14652491]\n",
      " [-0.2255507 ]] [ 0.77640688]\n",
      "400 818.946 [[ 1.09940243]\n",
      " [ 1.13535106]\n",
      " [-0.25118688]] [ 0.78129369]\n",
      "500 816.814 [[ 1.13594186]\n",
      " [ 1.12472045]\n",
      " [-0.27686441]] [ 0.78616822]\n",
      "600 814.727 [[ 1.1719929 ]\n",
      " [ 1.11461759]\n",
      " [-0.30258012]] [ 0.7910307]\n",
      "700 812.682 [[ 1.20756733]\n",
      " [ 1.10502815]\n",
      " [-0.32833159]] [ 0.79588115]\n",
      "800 810.678 [[ 1.24267673]\n",
      " [ 1.09593713]\n",
      " [-0.35411552]] [ 0.80071974]\n",
      "900 808.714 [[ 1.2773329 ]\n",
      " [ 1.0873313 ]\n",
      " [-0.37993029]] [ 0.80554646]\n",
      "1000 806.785 [[ 1.31154525]\n",
      " [ 1.07919753]\n",
      " [-0.40577254]] [ 0.8103615]\n",
      "1100 804.893 [[ 1.34532595]\n",
      " [ 1.07152176]\n",
      " [-0.43164009]] [ 0.81516498]\n",
      "1200 803.034 [[ 1.3786844 ]\n",
      " [ 1.06429195]\n",
      " [-0.45753059]] [ 0.81995696]\n",
      "1300 801.208 [[ 1.41163158]\n",
      " [ 1.05749452]\n",
      " [-0.48344141]] [ 0.82473761]\n",
      "1400 799.413 [[ 1.44417679]\n",
      " [ 1.05111825]\n",
      " [-0.50937057]] [ 0.82950699]\n",
      "1500 797.648 [[ 1.47632921]\n",
      " [ 1.04515123]\n",
      " [-0.53531551]] [ 0.83426523]\n",
      "1600 795.911 [[ 1.50809884]\n",
      " [ 1.03958142]\n",
      " [-0.56127417]] [ 0.83901238]\n",
      "1700 794.201 [[ 1.53949463]\n",
      " [ 1.03439808]\n",
      " [-0.58724499]] [ 0.84374815]\n",
      "1800 792.517 [[ 1.57052517]\n",
      " [ 1.02959013]\n",
      " [-0.6132251 ]] [ 0.84847295]\n",
      "1900 790.859 [[ 1.60119891]\n",
      " [ 1.02514744]\n",
      " [-0.63921309]] [ 0.85318702]\n",
      "2000 789.224 [[ 1.63152492]\n",
      " [ 1.02105868]\n",
      " [-0.66520697]] [ 0.85789043]\n",
      "789.224 [[ 1.63152492]\n",
      " [ 1.02105868]\n",
      " [-0.66520697]] [ 0.85789043]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    costvalue, weight, bvalue, _ = sess.run([cost, W, b, train], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, costvalue, weight, bvalue)\n",
    "        \n",
    "print(costvalue, weight, bvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 168.29859924]\n",
      " [ 196.5844574 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict={X:[[100,70,101], [90,100,80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step4. close the sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lec05 Logistic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step1. Build a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.div(1., 1. + tf.exp(tf.matmul(X,W)))\n",
    "## 1. 은 실행됨,, 1일떄는 실행 안됨\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)* tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if hypothesis >0.5, True / False --) cast in tf.float32 then 1 / 0\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step2. run a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[2,1],[3,1],[4,3]]\n",
    "y_data = [[1],[0],[0]]\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.65511119]\n",
      " [-0.42655259]] [-0.4299666]\n"
     ]
    }
   ],
   "source": [
    "for step in range(1000):\n",
    "    weight, bvalue, _ = sess.run([W,b, train], feed_dict={X:x_data, Y:y_data})\n",
    "print(weight, bvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step3. close the sess\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lec06 Softmax Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "os.chdir(\"C://Users//MinKyu//Desktop//모두의딥러닝\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- step1. make a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 4])\n",
    "Y = tf.placeholder(tf.float32, [None, 3])\n",
    "nb_classes = 3\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute = tf.matmul(X,W)+b\n",
    "#hypothesis = tf.nn.softmax(compute)\n",
    "hypothesis = tf.div(tf.exp(compute), tf.reduce_sum(tf.exp(compute)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- step2. run a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[7,1,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]]\n",
    "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.75585312 -0.02052454  0.12789632]\n",
      " [ 0.84199172 -1.09557688 -0.08057424]\n",
      " [-0.33622506 -0.33508578 -0.28135735]\n",
      " [-0.04821188  0.99117082 -0.27506155]] [-1.01747978 -0.97373509  1.93203259] 2.35553\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    weight, bvalue, costvalue, _ = sess.run([W,b,cost,optimizer],\n",
    "                                            feed_dict= {X:x_data, Y:y_data})\n",
    "print(weight, bvalue, costvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lec06-2 Fancy Softmax Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step1. make a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('lec06-2.txt', delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 7\n",
    "X = tf.placeholder(tf.float32, [None,16])\n",
    "Y = tf.placeholder(tf.int32, [None,1]) # 0~6\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes) # one_hot의 shape = (None,1,7)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes]) # shape = (None, 7)\n",
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute = tf.matmul(X,W)+b\n",
    "hypothesis = tf.nn.softmax(compute)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y_one_hot*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "# tf.cast = casts a tensor to a new type\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- step2. run a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:,[-1]]\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_data[0][0])\n",
    "type(y_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.421893 [[-0.01339065 -1.06268668  0.12599498  0.81963027  0.23437886  0.75443125\n",
      "   1.01244712]\n",
      " [-0.96918571  1.56861854 -1.12079096 -0.55996615  0.37604329  1.11136699\n",
      "   0.78118342]\n",
      " [-1.46843326  1.51470244 -0.40498489  1.08820915  0.02841981 -0.52440125\n",
      "   0.48511273]\n",
      " [ 1.66202283  0.21265434 -0.49519944 -0.71835315  0.3763316   0.03348056\n",
      "  -0.72002786]\n",
      " [-0.22797284  0.95440382 -0.15097398  1.85186672 -0.79587519  0.04724719\n",
      "  -1.76384199]\n",
      " [ 0.91688389 -0.1094542   2.011935    0.44191754 -0.05686411  0.86181378\n",
      "   2.26125526]\n",
      " [-0.24667281  0.329864    0.80039382  1.01362073 -0.35145438  0.01390979\n",
      "   0.49920949]\n",
      " [ 1.69439805 -0.51046538 -0.6123578  -1.02765393  1.74761546  0.43686965\n",
      "  -0.4832935 ]\n",
      " [ 0.4859165   1.08964837 -0.09934907 -0.39379933 -0.52900386 -1.26155734\n",
      "  -1.29338217]\n",
      " [ 1.01339936  0.11004823  2.29580307 -0.93528986 -0.26885995  1.03325689\n",
      "   0.68503106]\n",
      " [ 0.42823151  1.4786185   0.04124604 -1.01798213  1.53271782 -0.63243055\n",
      "   1.44459248]\n",
      " [-1.0084219  -1.79953218 -1.14875972  0.40560892  0.45675224 -1.08503699\n",
      "  -0.53649467]\n",
      " [ 0.30787116 -0.17629223 -0.28991747 -1.96271896  0.48413754  0.45292938\n",
      "   0.44048107]\n",
      " [-0.10757375 -0.65588439 -0.64334214  1.74569452 -0.20278648 -1.92768323\n",
      "  -0.71586108]\n",
      " [ 0.39479846  1.58390272  0.34920624 -1.8222909  -0.44372642  0.68586475\n",
      "  -0.37410581]\n",
      " [ 1.92208159  0.18243279 -1.89500213  1.45217037  0.24480122 -0.64146662\n",
      "  -0.00675393]] [-1.2974267  -0.49304852  0.26621783  0.43071732 -0.82394707  0.45625547\n",
      " -1.23827493]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    costvalue, weight, bvalue, _ = sess.run([cost, W, b, optimizer],\n",
    "                                           feed_dict={X: x_data, Y:y_data})\n",
    "print(costvalue, weight, bvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step3. predict the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred, acu = sess.run([prediction,accuracy], feed_dict={X:x_data, Y:y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.881188\n"
     ]
    }
   ],
   "source": [
    "print(acu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Lec07 training/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\",[None,4])\n",
    "Y = tf.placeholder(\"float\",[None,3])\n",
    "W = tf.Variable(tf.random_normal([4,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- arg_max의 dimension은 one_hot_encoding을 적용할 차원을 알려주는 매개변수이다.\n",
    "- 0은 열, 1은 행, 2는 면(행열)을 의미함\n",
    "- a1 = np.array([1,2,3]) #  크기 (3)인 1차원배열\n",
    "- a2 = np.array([ [1,2,3] ]) #  1x3\n",
    "- a3 = np.array( [ [1], [2], [3] ]) #  3x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hypothesis가 결과물이 [[a],[b],[c]] 이런식으로 나와 axis에 1 대입\n",
    "prediction = tf.argmax(hypothesis, axis = 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5]]\n",
    "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0]]\n",
    "x_test = [[1,2,5,6],[1,6,6,6],[1,7,7,7]]\n",
    "y_test = [[0,1,0],[0,0,1],[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.173331 [[-0.99160486 -0.95640808  0.55562723]\n",
      " [-0.15559673 -0.81849986 -0.48119408]\n",
      " [ 0.03673925 -0.06912151 -1.54703486]\n",
      " [-2.17426848  0.21271192 -0.58684093]]\n",
      "Prediction: [1 1 1]\n",
      "Accuracy: 0.333333\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# range(201) : 0~200을 포함하는 range 객체 생성\n",
    "for step in range(201):\n",
    "    cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                    feed_dict={X:x_data, Y:y_data})\n",
    "print(step, cost_val, W_val)\n",
    "print(\"Prediction:\", sess.run(prediction, feed_dict={X:x_test}))\n",
    "print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:x_test,Y:y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Big learning rate // small learning rate\n",
    "- non-normalizerd 돼있으면 회귀분석의 경우라도 tensorflow에서는\n",
    "- gradient descent를 이용해서 적합시키기에 발산할 수도있음\n",
    "- --) Have to normalize datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# one_hot = True : y값을 one_hot_encoding으로 읽음\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step1. make a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(hypothesis,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step2. run a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 2.906195059 0.712173\n",
      "Epoch: 0002 cost = 1.105622046 1.12848\n",
      "Epoch: 0003 cost = 0.884015113 0.726286\n",
      "Epoch: 0004 cost = 0.774217153 0.842699\n",
      "Epoch: 0005 cost = 0.705546678 0.780897\n",
      "Epoch: 0006 cost = 0.656266803 0.543357\n",
      "Epoch: 0007 cost = 0.618841848 0.586499\n",
      "Epoch: 0008 cost = 0.588645688 1.07342\n",
      "Epoch: 0009 cost = 0.563591176 0.30411\n",
      "Epoch: 0010 cost = 0.543051543 0.780991\n",
      "Epoch: 0011 cost = 0.524470025 0.585001\n",
      "Epoch: 0012 cost = 0.509155001 0.765588\n",
      "Epoch: 0013 cost = 0.495251439 0.864613\n",
      "Epoch: 0014 cost = 0.482929666 0.313063\n",
      "Epoch: 0015 cost = 0.471051418 0.884082\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={\n",
    "                            X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'cost =', '{:.9f}'.format(avg_cost), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58660144"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step3. close the sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Lec08 Tensor Manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[  1.,   2.,   3.],\n",
      "       [  4.,   5.,   6.],\n",
      "       [  7.,   8.,   9.],\n",
      "       [ 10.,  11.,  12.]])\n",
      "2\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[1.,2.,3.],[4.,5.,6.],[7.,8.,9.],[10.,11.,12.]])\n",
    "pp.pprint(t)\n",
    "print(t.ndim)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[13,14,15,16],[17,18,19,20],[21,22,23,24]]]])\n",
    "with tf.Session():\n",
    "    print(tf.shape(t).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Broadcasting : Operations between the same shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  6.]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3.,3.]])\n",
    "matrix2 = tf.constant(3.)\n",
    "with tf.Session():\n",
    "    print((matrix1+matrix2).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.  6.]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[1.,2.]])\n",
    "matrix2 = tf.constant([3.,4.])\n",
    "with tf.Session():\n",
    "    print((matrix1+matrix2).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Reduce_mean or reduce_sum or argmax : floating point를 사용해야함\n",
    "- 0 : 행방향\n",
    "- 1 : 열방향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "[ 2.  3.]\n",
      "[ 1.5  3.5]\n",
      "[ 1.5  3.5]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "x = [[1.,2.],[3.,4.]]\n",
    "with tf.Session():\n",
    "    print(tf.reduce_mean(x).eval())\n",
    "    print(tf.reduce_mean(x, axis=0).eval())\n",
    "    print(tf.reduce_mean(x, axis=1).eval())\n",
    "    print(tf.reduce_mean(x, axis=-1).eval())\n",
    "    print(tf.argmax(x, axis=0).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Reshape - '-1'의 의미\n",
    "- (2,2,3) 이므로 [-1,3]이면 [4,3]이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "[[[ 0  1  2]]\n",
      "\n",
      " [[ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session():\n",
    "    print(tf.reshape(t, shape = [-1,3]).eval())\n",
    "    print(tf.reshape(t, shape = [-1,1,3]).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape - 'squeeze', 'expand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[[0]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session():\n",
    "    print(tf.squeeze([[0],[1],[2]]).eval())\n",
    "    print(tf.expand_dims([0,1,2],1).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0.  1.]]\n",
      "\n",
      " [[ 1.  0.  0.]]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session():\n",
    "    print(tf.one_hot([[0],[1],[2],[0]], depth=3).eval())\n",
    "    t= tf.one_hot([[0],[1],[2],[0]], depth=3)\n",
    "    print(tf.reshape(t,shape=[-1,3]).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casting\n",
    "- 변수 형태를 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session():\n",
    "    print(tf.cast([1.8, 2.2, 3.3, 4.9], tf.int32).eval())\n",
    "    print(tf.cast([True, False, 1==1, 0==1], tf.int32).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack - data를 쌓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "x=[1,4]\n",
    "y=[2,5]\n",
    "z=[3,6]\n",
    "\n",
    "with tf.Session():\n",
    "    print(tf.stack([x,y,z]).eval())\n",
    "    print(tf.stack([x,y,z], axis=1).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ones and Zeros_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 1 1]]\n",
      "[[0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "x = [[0,1,2], [2,1,0]]\n",
    "with tf.Session():\n",
    "    print(tf.ones_like(x).eval())\n",
    "    print(tf.zeros_like(x).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "2 5\n",
      "3 6\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip([1,2,3], [4,5,6]):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lec09-1. Neural Net for XOR\n",
    "- Lec09-2. Tensorboard\n",
    "- decide which tensors you want to log\n",
    "- Merge all summaries\n",
    "- Create writer and add graph\n",
    "- Run summary merge and add_summary\n",
    "- Launch TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.array로 지정할 때, np.float32 꼭 써줘야함!!\n",
    "x_data = np.array([[0.,0.],\n",
    "                   [0.,1.],\n",
    "                   [1.,0.],\n",
    "                   [1.,1.]], dtype=np.float32) # 4 x 2\n",
    "y_data = np.array([[0.],\n",
    "                   [1.],\n",
    "                   [1.],\n",
    "                   [0.]], dtype = np.float32) # 4 x 1\n",
    "\n",
    "X = tf.placeholder(dtype= tf.float32, shape = [None,2])\n",
    "# Y의 shape을 [None]으로 했더니 오류남....\n",
    "Y = tf.placeholder(dtype=tf.float32, shape = [None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"layer1/weight1:0\", shape=(2, 6), dtype=float32_ref) must be from the same graph as Tensor(\"Placeholder:0\", shape=(?, 2), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d55dda393c1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bias1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#layer1 = tf.sigmoid(tf.matmul(X,w1)+b1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mlayer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# 1. decide which tensors you want to log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   1790\u001b[0m       \u001b[0mare\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m   \"\"\"\n\u001b[1;32m-> 1792\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1793\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Only one of transpose_a and adjoint_a can be True.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(name, default_name, values)\u001b[0m\n\u001b[0;32m   4519\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4520\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4521\u001b[1;33m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4522\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4523\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   4260\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4261\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4262\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4263\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4264\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   4199\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4200\u001b[0m     raise ValueError(\n\u001b[1;32m-> 4201\u001b[1;33m         \"%s must be from the same graph as %s.\" % (item, original_item))\n\u001b[0m\u001b[0;32m   4202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"layer1/weight1:0\", shape=(2, 6), dtype=float32_ref) must be from the same graph as Tensor(\"Placeholder:0\", shape=(?, 2), dtype=float32)."
     ]
    }
   ],
   "source": [
    "# Tensor들을 Layer로 나눔.\n",
    "# TensorBoard를 이용해 시각화하기 위한 Tensor 추가\n",
    "with tf.Graph().as_default():\n",
    "    with tf.name_scope(\"layer1\") as scope:\n",
    "        w1 = tf.Variable(tf.random_normal([2,6]), name='weight1', dtype=tf.float32)\n",
    "        b1 = tf.Variable(tf.random_normal([6]), name='bias1', dtype=tf.float32)\n",
    "        #layer1 = tf.sigmoid(tf.matmul(X,w1)+b1)\n",
    "        layer1 = tf.matmul(X,w1)+b1\n",
    "        \n",
    "        # 1. decide which tensors you want to log\n",
    "        #w1_hist = tf.summary.histogram(\"weights1\", w1)\n",
    "        #b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "        #layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "    \n",
    "\n",
    "    with tf.name_scope(\"layer2\") as scope:\n",
    "        w2 = tf.Variable(tf.random_normal([6,1]), name = 'weight2', dtype=tf.float32)\n",
    "        b2 = tf.Variable(tf.random_normal([1]), name = 'bias2', dtype=tf.float32)\n",
    "        hypothesis = tf.sigmoid(tf.matmul(layer1,w2)+b2)\n",
    "        \n",
    "        w2_hist = tf.summary.histogram(\"weights2\", w2)\n",
    "        b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "        hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "    \n",
    "\n",
    "\n",
    "    with tf.name_scope(\"cost\") as scope:\n",
    "        cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "        cost_summ = tf.summary.scalar(\"cost\",cost)\n",
    "    \n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "    \n",
    "    with tf.name_scope(\"prediction\") as scope:\n",
    "        predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "        accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-66f2a95f8e0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# 4. Run summary merge and add_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "route = os.getcwd()\n",
    "# 2. Merge all summaries\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "# 3. Create writer and add graph\n",
    "writer = tf.summary.FileWriter(\"./Tensorboard\", sess.graph)\n",
    "#writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "for step in range(10001):\n",
    "    # 4. Run summary merge and add_summary\n",
    "    s, _ = sess.run([summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "    writer.add_summary(s, global_step=step)\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(step, sess.run(cost, \n",
    "                             feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "# Accuracy report\n",
    "h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                    feed_dict={X: x_data, Y: y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- lec10. mnist_nn, xavier initialization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- step1. make a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input layer\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define FC Layer function\n",
    "def nn_layer(name, input_data, output_size):\n",
    "    w = tf.get_variable(name = name + \"_w\", \n",
    "                        shape = [input_data.get_shape().as_list()[1], output_size],\n",
    "                        # tensor의 모양 get_shape()\n",
    "                        initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(name = name + \"_b\",\n",
    "                       shape = [output_size],\n",
    "                       initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.matmul(input_data, w) + b\n",
    "\n",
    "# FC Layer\n",
    "with tf.name_scope(\"L2\"): # [?, 784] --) [?, 14*14]\n",
    "    L2 = tf.nn.relu(nn_layer(\"L2\", X, 14*14 ))\n",
    "    L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "with tf.name_scope(\"L3\"): # [?, 14*14] --) [?, 14*14]\n",
    "    L3 = tf.nn.relu(nn_layer(\"L3\", L2, 14*14))\n",
    "    L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "\n",
    "with tf.name_scope(\"L4\"): # [?, 14*14] --) [?, 10]\n",
    "    hypothesis = nn_layer(\"L4\", L3, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss Layer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy Layer\n",
    "is_correct = tf.equal(tf.argmax(hypothesis,1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- step2. Run a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.388544917\n",
      "Epoch: 0002 cost = 0.300527055\n",
      "Epoch: 0003 cost = 0.273248309\n",
      "Epoch: 0004 cost = 0.255698043\n",
      "Epoch: 0005 cost = 0.254622058\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bbf91fccb08e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             c, _ = sess.run([cost, optimizer], \n\u001b[1;32m---> 13\u001b[1;33m                             feed_dict = { X : batch_xs, Y : batch_ys, keep_prob : 0.7})\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize Tensorflow Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training Cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size) # epoch당 batch수\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], \n",
    "                            feed_dict = { X : batch_xs, Y : batch_ys, keep_prob : 0.7})\n",
    "            avg_cost += c/total_batch\n",
    "            \n",
    "        print('Epoch:', '%04d' % (epoch+1),\n",
    "             'cost =', '{:.9f}'.format(avg_cost))\n",
    "    print('Accuracy:', sess.run(accuracy,\n",
    "                                feed_dict={X : mnist.test.images, Y : mnist.test.labels, keep_prob : 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Lec 11. MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- step1. make the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1,28,28,1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conv Layer1 : input : [?, 28, 28 ,1] \n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\") # [28,28,32]\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "# Max-pool Layer1\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\") # [14,14,32]\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "# Conv Layer2 : input : [?, 14, 14, 32]\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01)) \n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME') # [14, 14, 64]\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "# Max-Pool Layer2\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME') # [7, 7, 64]\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "# Conv Layer3 : [?, 7, 7, 64]\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME') # [7, 7, 128]\n",
    "L3 = tf.nn.relu(L3)\n",
    "\n",
    "# Max-Pool Layer3\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob) # [4, 4, 128]\n",
    "L3 = tf.reshape(L3, [-1, 128 * 4 * 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FC Layer1 : [?, 128*4*4] --) [?, 625]\n",
    "W4 = tf.get_variable(\"W4\", shape = [128 * 4 * 4, 625],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4 )\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "# FC Layer2 : [?, 625] --) [?, 10]\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss Layer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy Layer\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- step2. Run a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-24f94e9e51a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m# batch별로 optimize 시킴\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             c, _ = sess.run([cost, optimizer],\n\u001b[1;32m---> 13\u001b[1;33m                            feed_dict = {X : batch_xs, Y : batch_ys, keep_prob : 0.7})\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MinKyu\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('Learning started. It takes sometime.')\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size) # epoch당 batch수\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # batch별로 optimize 시킴\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                           feed_dict = {X : batch_xs, Y : batch_ys, keep_prob : 0.7})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch:', '%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print('Learning Finished')\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
